{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb96308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import io, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ff8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_samples = 0.2 #seconds\n",
    "size_max = 120000\n",
    "frequence = 10000 #Hertz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3eb9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"dataset.mat\"\n",
    "\n",
    "dataset = scipy.io.loadmat(file)\n",
    "\n",
    "df_normal = dataset[\"normal\"].reshape(-1)[:size_max]\n",
    "df_inner = dataset[\"inner\"].reshape(-1)[:size_max]\n",
    "df_roller = dataset[\"roller\"].reshape(-1)[:size_max]\n",
    "df_outer = dataset[\"outer\"].reshape(-1)[:size_max]\n",
    "\n",
    "data = [df_normal,df_inner,df_roller,df_outer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe1d4d",
   "metadata": {},
   "source": [
    "0- normal defect\n",
    "1- inner defect\n",
    "2- roller defect\n",
    "3- outer defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f547c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train=0.7):\n",
    "    type_track = 0\n",
    "    n_samples_each = int(size_max/frequence/duration_samples)\n",
    "    audios_train = []\n",
    "    audios_test = []\n",
    "    number_train=int(n_samples_each*0.7)\n",
    "\n",
    "    for track in data:\n",
    "        for i in range(0,n_samples_each):\n",
    "            t1 = int(i*frequence*duration_samples)\n",
    "            t2 = int((i+1)*frequence*duration_samples)\n",
    "            new = list(track)[t1:t2]\n",
    "            if i<number_train:\n",
    "                audios_train.append((type_track,new))\n",
    "            else:\n",
    "                audios_test.append((type_track,new))\n",
    "        type_track = type_track+1\n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(audios_train)\n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(audios_test)\n",
    "    return [i[1] for i in audios_train], [i[1] for i in audios_test], [i[0] for i in audios_train], [i[0] for i in audios_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4654ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_train, audios_test, label_train, label_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a06099fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(audios_train[2], rate=frequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b5376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audios_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a1b79f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=2000\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-122.66910248,  -92.38567051,  -90.14709196,  -95.04445657],\n",
       "       [  65.11893795,   65.22694178,   65.74420185,   62.49582789],\n",
       "       [ -23.78778531,  -22.8203103 ,  -24.81519375,  -24.33575148],\n",
       "       [  33.9697855 ,   36.7075763 ,   38.60036311,   39.16014693],\n",
       "       [  19.13609532,   18.71309184,   18.6506835 ,   20.118161  ],\n",
       "       [ -14.59032857,  -14.31039357,  -13.29117492,  -11.43985052],\n",
       "       [  -3.7035524 ,   -6.63739772,  -10.82981239,  -11.13944179],\n",
       "       [   7.87573437,    2.31676845,    1.22366204,    2.58736084],\n",
       "       [ -20.97423589,  -18.75185994,  -18.8267292 ,  -15.36336298],\n",
       "       [  11.01888393,    8.41455642,    2.4582269 ,    6.09945736],\n",
       "       [   7.08547832,    6.72868892,    4.85371586,    4.597242  ],\n",
       "       [  -8.27849928,  -13.05751705,  -12.613952  ,  -12.84161621],\n",
       "       [ -12.54682523,  -15.42040138,  -13.41485823,  -13.03844075],\n",
       "       [  -6.00353258,   -5.68629068,   -6.50225963,   -4.82829332],\n",
       "       [   5.21023325,    4.02892914,    3.76706342,    6.05492533],\n",
       "       [ -21.2730799 ,  -22.15999507,  -21.51204115,  -22.25497048],\n",
       "       [   5.993293  ,    4.26346459,    6.72744746,    3.68836593],\n",
       "       [   6.37508376,    3.92386404,    5.62023151,    5.62199268],\n",
       "       [  -8.57010734,   -6.14870629,   -6.31892249,   -7.29787548],\n",
       "       [   0.935751  ,    3.09717771,    1.3147784 ,    3.64669251]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "y= np.array(audios_train[0])\n",
    "sr=frequence\n",
    "# audio_data, sample_rate= librosa.load(y=y,sr=sr)\n",
    "mfcc= librosa.feature.mfcc(y=y,sr=sr)\n",
    "mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b647b1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ae6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(l):\n",
    "    y=np.array(l)\n",
    "    sr=frequence\n",
    "    mfcc= librosa.feature.mfcc(y=y,sr=sr)\n",
    "    mfcc_scaled=np.mean(mfcc.T, axis=0)\n",
    "    \n",
    "    return mfcc_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68bf9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "i=0\n",
    "for audio in audios_train:\n",
    "    data=feature_extract(audio)\n",
    "    label= label_train[i]\n",
    "    extracted_features.append([data,label])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccde7b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-100.06158038013302, 64.64647736755063, -23.9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[35.74615329316609, -53.1169484254411, 4.16197...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-101.55683725535413, 62.47573651477131, -24.4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[40.669772226180235, -51.51024941922913, 1.916...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-63.955624976208675, 13.54734617515508, -25.1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [-100.06158038013302, 64.64647736755063, -23.9...      0\n",
       "1  [35.74615329316609, -53.1169484254411, 4.16197...      3\n",
       "2  [-101.55683725535413, 62.47573651477131, -24.4...      0\n",
       "3  [40.669772226180235, -51.51024941922913, 1.916...      3\n",
       "4  [-63.955624976208675, 13.54734617515508, -25.1...      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(extracted_features, columns=['feature','class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bcc46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into dependent and independent features\n",
    "x=np.array(df['feature'].tolist())\n",
    "y=np.array(df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecdf608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61321337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e000c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical  \n",
    "import numpy as np\n",
    "y_hot_train = to_categorical(y,num_classes =4)\n",
    "y_hot_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b87db25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hot_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278578c",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abba86c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e27b8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bfeb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y_hot_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5b54cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2508/2902804284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\keras\\dtensor\\utils.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m           \u001b[0mlayout_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_layout\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0minit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_instance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m# Inject the layout parameter after the invocation of __init__()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f47a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(20,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "683d97a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'summery'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2508/3816585142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'summery'"
     ]
    }
   ],
   "source": [
    "model.summery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af864b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7f5bf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 5ms/step - loss: 16.5280 - accuracy: 0.2500\n",
      "Training completed in time:  0:00:01.130302\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "#                                verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x,y_hot_train)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56ec11be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6726190447807312\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(x,y_hot_train,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d4d01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.array(audios_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97054b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20d1147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=2000\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_dummy= feature_extract(audios_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "970c326c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dummy.shape\n",
    "test_dummy= test_dummy.reshape(1,-1)\n",
    "test_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50406117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.8920269e-04, 9.3718070e-01, 3.4559824e-02, 2.7570259e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans= model.predict(test_dummy)\n",
    "ans\n",
    "# so predicted class is 1\n",
    "# index of max of this array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86146e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test[0]\n",
    "# hence predicting correct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f1837c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2=np.array(audios_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28ad9ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0233b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
